<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Speech perception and generalization across talkers and accents &#8211; Kodi Weatherholtz</title>
<meta name="description" content="New manuscript on how listeners cope with variability in speech">
<meta name="keywords" content="speech perception, adaptation, normalization, invariance, motor theory">



<!-- Twitter Cards -->
<meta name="twitter:title" content="Speech perception and generalization across talkers and accents">
<meta name="twitter:description" content="New manuscript on how listeners cope with variability in speech">
<meta name="twitter:site" content="@kweather">
<meta name="twitter:creator" content="@kweather">

<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://kweatherholtz.github.io/images/profile-photo.jpg">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Speech perception and generalization across talkers and accents">
<meta property="og:description" content="New manuscript on how listeners cope with variability in speech">
<meta property="og:url" content="http://kweatherholtz.github.io/blog/speech-perception-and-generalization/">
<meta property="og:site_name" content="Kodi Weatherholtz">





<link rel="canonical" href="http://kweatherholtz.github.io/blog/speech-perception-and-generalization/">
<link href="http://kweatherholtz.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="Kodi Weatherholtz Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://kweatherholtz.github.io/assets/css/main.css">
<!-- Webfonts -->
<script src="https://use.edgefonts.net/source-sans-pro:n2,i2,n3,i3,n4,i4,n6,i6,n7,i7,n9,i9;source-code-pro:n4,n7;volkhov.js"></script>

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
  <script src="http://kweatherholtz.github.io/assets/js/vendor/html5shiv.min.js"></script>
  <script src="http://kweatherholtz.github.io/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="http://kweatherholtz.github.io/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>


<!-- MathJax -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://kweatherholtz.github.io/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://kweatherholtz.github.io/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://kweatherholtz.github.io/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://kweatherholtz.github.io/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://kweatherholtz.github.io/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://kweatherholtz.github.io/images/apple-touch-icon-144x144-precomposed.png">

</head>

<body id="post">

<div class="navigation-wrapper">
	<nav role="navigation" id="site-nav" class="animated drop">
	    <ul>
      
		    
		        
		    
		    <li><a href="http://kweatherholtz.github.io/" >About</a></li>
		  
		    
		        
		    
		    <li><a href="http://kweatherholtz.github.io/cv/weatherholtz_cv.pdf" >CV</a></li>
		  
		    
		        
		    
		    <li><a href="http://kweatherholtz.github.io/#contact" >Contact</a></li>
		  
		    
		        
		    
		    <li><a href="http://kweatherholtz.github.io/#publications" >Publications</a></li>
		  
		    
		        
		    
		    <li><a href="http://kweatherholtz.github.io/#research" >Research</a></li>
		  
		    
		        
		    
		    <li><a href="http://kweatherholtz.github.io/#teaching" >Teaching</a></li>
		  
		    
		        
		    
		    <li><a href="http://kweatherholtz.github.io/#blog" >Blog</a></li>
		  
		    
		        
		    
		    <li><a href="http://kweatherholtz.github.io/search/" >Search</a></li>
		  
	    </ul>
	</nav>
</div><!-- /.navigation-wrapper -->

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->

<div class="js-menu-screen menu-screen"></div>




<div id="main" role="main">
  <article class="hentry">
    
    <div class="entry-wrapper">
      <header class="entry-header">
        
          <h1 class="entry-title">Speech perception and generalization across talkers and accents</h1>
        
        <span class="entry-tags"><a href="http://kweatherholtz.github.io/tags/#speech perception" title="Pages tagged speech perception">speech perception</a>&nbsp;&bull;&nbsp;<a href="http://kweatherholtz.github.io/tags/#adaptation" title="Pages tagged adaptation">adaptation</a>&nbsp;&bull;&nbsp;<a href="http://kweatherholtz.github.io/tags/#normalization" title="Pages tagged normalization">normalization</a>&nbsp;&bull;&nbsp;<a href="http://kweatherholtz.github.io/tags/#invariance" title="Pages tagged invariance">invariance</a>&nbsp;&bull;&nbsp;<a href="http://kweatherholtz.github.io/tags/#motor theory" title="Pages tagged motor theory">motor theory</a></span>
      </header>
      <footer class="entry-meta">
        
        
        
          <img src="http://kweatherholtz.github.io/images/profile-photo.jpg" class="bio-photo" alt="Kodi Weatherholtz bio photo"></a>
        
        <span class="author vcard">By <span class="fn">Kodi Weatherholtz</span></span>
        <span class="entry-date date published"><time datetime="2015-08-06T20:57:20-04:00"><i class="fa fa-calendar-o"></i> August 06, 2015</time></span>
        
        <span class="entry-comments"><i class="fa fa-comment-o"></i> <a href="#disqus_thread">Comment</a></span>
        <span class="social-share-twitter">
  <a href="https://twitter.com/intent/tweet?hashtags=speechperception,adaptation,normalization,invariance,motortheory&amp;text=Speech%20perception%20and%20generalization%20across%20talkers%20and%20accents&amp;url=http://kweatherholtz.github.io/blog/speech-perception-and-generalization/&amp;via=kweather" title="Share on Twitter" itemprop="Twitter"><i class="fa fa-twitter-square"></i> Tweet</a>
</span>
<span class="social-share-facebook">
  <a href="https://www.facebook.com/sharer/sharer.php?u=http://kweatherholtz.github.io/blog/speech-perception-and-generalization/" title="Share on Facebook" itemprop="Facebook"><i class="fa fa-facebook-square"></i> Like</a>
</span>
<span class="social-share-googleplus">
  <a href="https://plus.google.com/share?url=http://kweatherholtz.github.io/blog/speech-perception-and-generalization/" title="Share on Google Plus" itemprop="GooglePlus"><i class="fa fa-google-plus-square"></i> +1</a>
</span>
<!-- /.social-share -->
        
      </footer>
      <div class="entry-content">
        <p>Florian Jaeger and I recently submitted a research review on <a href="https://www.academia.edu/14122668/Speech_perception_and_generalization_across_speakers_and_accents">“Speech perception and
generalization across talkers and accents”</a>, which provides an overview
of the critical concepts and debates in this domain of research. The
manuscript is still under review, but we wanted to share the current
version. Of course, feedback is always welcome.</p>

<p>In this paper, we review the mixture of processes that enable robust
understanding of speech across talkers despite the <em>lack of invariance</em>.
These processes include (i) automatic pre-speech adjustments of the
distribution of energy over acoustic frequencies (<strong><em>normalization</em></strong>); (ii)
sensitivity to category-relevant acoustic cues that are invariant across
talkers (<strong><em>acoustic invariance</em></strong>); (iii) sensitivity to
articulatory/gestural cues, which can be perceived directly
(<strong><em>audio-visual integration</em></strong>) or recovered from the acoustic signal
(articulatory recovery); (iv) implicit statistical learning of
talker-specific properties (<strong><em>adaptation, perceptual recalibration</em></strong>); and
(v) the use of past experiences (e.g., specific exemplars) and
structured knowledge about pronunciation variation (e.g., patterns of
variation that exist across talkers with the same accent) to guide
speech perception (<strong><em>exemplar-based recognition</em></strong>, <strong><em>generalization</em></strong>).</p>

<p>While there is substantial compelling evidence for each of these
processes, none currently provides a sufficient account of how listeners
cope with variability in speech. In our research overview, we highlight
the successes and limitations of these various approaches. More
importantly, we emphasize overlap and complementarity among lines of
research that are often viewed as orthogonal or opposing (e.g.,
normalization and statistical learning).</p>

<p>In our view, it is the integration of these various processes that is
the big open question in research on speech perception. Integrating
these accounts is by no means trivial, as evidenced by the on-going
debate in speech perception concerning normalization, exemplar-based and
statistical learning accounts. However, we believe that reexamining the
basic assumptions that underlie these accounts will help point the way
forward.</p>

<p>For example, consider normalization. Normalization is often
conceptualized as an automatic low-level process that stems from basic
aspects of the auditory perceptual system and hence does not involve
learning. Historically, one of the major successes of the normalization
approach to speech perception is accounting for how listeners cope with
variability due to vocal tract differences across talkers: e.g.,
interpreting category-relevant acoustic cues (such as \(F_1\) and \(F_2\) for
vowels) with respect to acoustic cues that provide an estimate of the
talker’s vocal tract characteristics (e.g., \(F_0\) and \(F_3\); see Figure 1). The basic
ability to interpret speech cues in relation to one another (e.g., \(F_1\)
relative to \(F_3\)) might stem from biologically-determined aspects of the
auditory system. However, the use of specific cues like \(F_0\) and \(F_3\) as the
basis for normalization might stem from statistical learning during
early development about the relationship between a talker’s vocal tract
size and corresponding vocal tract resonances.</p>

<figure>
	<a href="/images/vowel_space_male-vs-female.jpg"><img src="/images/vowel_space_male-vs-female.jpg" alt="image" /></a>
	<figcaption>Example of cross-talker vowel variability before (left)
	and after (right) normalizing for differences in vocal-tract length
	based on F3. <b>Top Panel</b>: the average vowel space for adult male and
	adult female talkers in the vowel corpus collected by Hillenbrand et
	al. (1995). Talkers in this corpus are from the Northern dialect
	region of American English. <b>Bottom Panel</b>: the degree of overlap
	among adult male productions of /ʊ/ and adult female productions of
	/u/. Plots show individual vowel tokens (small dots), category means
	(large dots), and 95% confidence ellipses. Note that the unnormalized male and female vowel spaces (<b>top left
	panel</b>) have approximately the same geometric configuration, but the
	male vowels are characterized by comparatively lower absolute F1 and
	F2 values, which reflects the fact that longer vocal tracts resonate
	at lower frequencies than shorter vocal tracts. As a result, the
	distribution of adult male tokens of /ʊ/ is highly overlapping with
	the distribution of adult female tokens of /u/ in F1xF2 space
	(<b>bottom left panel</b>). That is, the same acoustic information maps
	onto different phonological categories with different probabilities
	depending on the talker’s sex. Hence neither F1 nor F2 provides
	reliable information for discriminating these vowel categories
	across talker sex (bottom left panel, dark grey bar). Normalizing F1
	and F2 based on F3 (which is correlated with vocal tract length)
	considerably reduces the difference between the average male and
	female vowel spaces (<b>top right panel</b>), while preserving the overall
	shape of the space (i.e., the relative position of vowels). As a
	result of F3-normalization, tokens of /ʊ/ and /u/ are less overlapping (<b>bottom right panel</b>) and, hence, more discriminable
	despite vocal tract differences across talkers.</figcaption>
</figure>

<p>In other words, <strong>low-level normalization might be the outcome of
statistical learning</strong>. If so, this would enable us to situate a wide
range of perceptual phenomena along a continuum of statistical learning
that operates at various time scales and at various levels of
granularity. Phenomena like talker-specific phonetic recalibration
(i.e., fine-tuning phonetic category boundaries according to
talker-specific cue distributions) are situated at one end of the
continuum — as these adjustments occur continuously in response to the
statistics of the ambient environment. Phenomena like vocal tract
normalization might form the other end of the continuum — as listeners
(in principle) only need to learn once, presumably during early
development, about how the size and the shape of the vocal tract affect
the distribution of energy at certain frequency ranges. Presumably (and
speculatively), if the statistical patterns are sufficiently robust
across talkers (e.g., the relationship between vocal tract
characteristics and \(F_0\) or \(F_3\)), then it would be beneficial (i.e.,
efficient) for the speech perception system to have evolved to adjust
for this relationship at an early stage of processing (e.g., automatic
low-level “normalization”). For statistical patterns that are specific
to particular talkers or groups, perhaps the relevant perceptual
adjustments occur at a later stage of processing (e.g., the mapping of
percepts to higher-level categories).</p>

<p>This emphasis on statistical learning might also provide traction in the
debate between normalization and exemplar-based accounts of speech
perception. As has been discussed extensively in the literature, one of
the <strong>primary criticisms of normalization accounts</strong> is that fine stimulus
details are not “filtered out” during perception — as often implicitly
or explicitly assumed in normalization proposals — but rather these
details are encoded in memory and influence subsequent processing. In
turn, one <strong>criticism of exemplar-based approaches</strong> is that they do not
provide a straight forward account for some of the most compelling
evidence of low-level normalization: i.e., that speech sounds are
interpreted relative to frequency information in the surrounding
context, even when this “context” is non-speech sine-wave tones (see
work by Holt and colleagues).</p>

<p>These criticisms indicate that <strong>neither normalization nor exemplar-based
accounts are sufficient</strong>. Perhaps these accounts are not contradictory,
but rather form part of a complex speech perception system that is
capable of statistical learning at various time scales and levels of
granularity. Statistical learning in speech involves pattern abstraction
over a distribution of speech episodes. Thus, if both talker
normalization (i.e., sensitivity to talker invariant information) and
talker-specific speech perception can be conceptualized as the result of
statistical learning (potentially at different time scales), then there
is no debate about the storage of episodic information. Rather, the
central questions concern how the learning is implemented and the
conditions under which learning leads to low-level versus higher-level
adjustments in how speech stimuli are perceived.</p>


        
          <div id="disqus_thread"></div><!-- /#disqus_thread -->
          
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'kodiweatherholtz'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'https://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

        
      </div><!-- /.entry-content -->
    </div><!-- /.entry-wrapper -->
    <nav class="pagination" role="navigation">
      
        <a href="http://kweatherholtz.github.io/blog/intro-to-ggplot/" class="btn" title="An introduction to ggplot">Previous</a>
      
      
    </nav><!-- /.pagination -->
  </article>
</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo" class="entry-wrapper">
    

<span>&copy; 2015 Kodi Weatherholtz. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="http://mademistakes.com/so-simple/" rel="nofollow">So Simple Theme</a>.</span>
<div class="social-icons">
	<a href="https://rochester.academia.edu/KodiWeatherholtz" title="Kodi Weatherholtz on Academia.edu" target="_blank">
	<span class="fa-stack fa-lg">
	<i class="fa fa-circle fa-stack-2x"></i>
	<i class="fa fa-font fa-stack-1x" style="color:black"></i></span></a>

	<a href="https://twitter.com/kweather" title="Kodi Weatherholtz on Twitter" target="_blank">  	
	<span class="fa-stack fa-lg">
	<i class="fa fa-circle fa-stack-2x"></i>
	<i class="fa fa-twitter fa-stack-1x fa-inverse" style="color:black"></i></span></a>

	

	

	

	

	

	

	<a href="https://github.com/kweatherholtz" title="Kodi Weatherholtz on Github" target="_blank"><span class="fa-stack fa-lg"><i class="fa fa-github fa-2x"></i></span></a>

	

  

	
  
  <a href="http://kweatherholtz.github.io/feed.xml" title="Atom/RSS feed">
  	<span class="fa-stack fa-lg">
	<i class="fa fa-circle fa-stack-2x"></i>
	<i class="fa fa-rss fa-stack-1x fa-inverse" style="color:black"></i></span></a>
</div><!-- /.social-icons -->

  </footer>
</div><!-- /.footer-wrapper -->

<script type="text/javascript">
  var BASE_URL = 'http://kweatherholtz.github.io';
</script>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://kweatherholtz.github.io/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://kweatherholtz.github.io/assets/js/scripts.min.js"></script>




</body>
</html>
